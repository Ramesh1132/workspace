package com.pgtest


import org.apache.spark.SparkConf
import org.apache.spark.streaming.StreamingContext
import org.apache.spark.streaming.Seconds
import org.apache.spark.streaming._
import org.apache.spark.streaming.kafka.KafkaUtils 
import org.apache.log4j.{Logger,Level}
import com.datastax.spark.connector.cql.CassandraConnector
import com.datastax.spark.connector.streaming._
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import com.datastax.spark.connector._
import com.datastax.spark.connector.rdd._
import org.apache.spark.sql.cassandra._
import com.datastax.spark.connector.cql.CassandraConnector
import java.util.Date
import org.apache.spark.sql._


class sample(id1: String, id2: String,id3: String,id4: String,id5: String,id6: String,id7: String,id8: String,id9: String,id10: String,id11: String,id12: String,id13: String,id14: String,id15: String,id16: String,id17: String,id18: String,id19: String,id20: String,id21: String,id22: String,id23: String,id24: String,id25: String)
object MorColums {
  
  def main(args : Array[String]) {
    
    Logger.getLogger("org").setLevel(Level.OFF)
    Logger.getLogger("akka").setLevel(Level.OFF)
    
    
    val conf = new SparkConf().setMaster("local[*]").setAppName("KafkaReceiver") .set("spark.driver.allowMultipleContexts", "true").set("spark.cassandra.connection.host","localhost")        

val ssc = new StreamingContext(conf, Seconds(5))
   
 

val kafkaStream = KafkaUtils.createStream(ssc, "localhost:2181","spark-streaming-consumer-group", Map("test" -> 1))
val rdd1 = kafkaStream.map(_._2)
rdd1.foreachRDD { rdd =>
  val sqlContext = SQLContext.getOrCreate(rdd.sparkContext)
      import sqlContext.implicits._
        
        sqlContext.read.json(rdd).registerTempTable("eventTable")

        val eventdf1 = sqlContext.sql("SELECT * FROM eventTable")


        eventdf1.collect.foreach(println)

        val eventdf = sqlContext.sql("SELECT sensor, sendtime,data.actor FROM eventTable")
        eventdf.printSchema()
       // eventdf.map {
        //  case (r) => (r.getString(0) + count, sendtime, count,eventdf1)
      //  }
       //   .saveToCassandra("c", "event", SomeColumns("sensor", "sendtime", "count","entireJson"))

      }
      
   


 
  ssc.start()
ssc.awaitTermination()

  }
}