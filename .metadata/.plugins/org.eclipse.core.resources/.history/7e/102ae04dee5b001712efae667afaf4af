package com.pgtest
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.sql.SQLContext

object Task {
  def main(args : Array[String]){
 val conf = new SparkConf().setMaster("local[2]").setAppName("my app")
    val sc = new SparkContext(conf);
 val sparksql = new SQLContext(sc)
 
 //val a = 1;
 //val b = 2;
// val c = a.join(b);
 //val rdd = sparksql.json.read("")
   //val spark = org.apache.spark.sql.SparkSession.builder
        //.master("local")
        //.appName("Spark CSV Reader")
      //  .getOrCreate;
    //val df = spark.read
        //.format("com.databricks.spark.csv")
        //.option("header", "true") 
        //.option("mode", "DROPMALFORMED")
      //  .load("C:/Users/nageswara.rao.dasari/Downloads/MOCK_DATA (2).csv"); 

    
    //val rdd = sc.textFile("C:/Users/nageswara.rao.dasari/Downloads/MOCK_DATA (2).csv")
 }
}