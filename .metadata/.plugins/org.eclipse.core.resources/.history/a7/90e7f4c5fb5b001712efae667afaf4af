package com.pgtest
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import org.apache.spark.sql.SQLContext

object Task {
  def main(args : Array[String]){
 val conf = new SparkConf().setMaster("local[2]").setAppName("my app")
    val sc = new SparkContext(conf);
 val sparksql = new SQLContext(sc)
 
 //val a = 1;
 //val b = 2;
// val c = a.join(b);
 //val rdd = sparksql.json.read("")
   //val spark = org.apache.spark.sql.SparkSession.builder
        //.master("local")
        //.appName("Spark CSV Reader")
      //  .getOrCreate;
    //val df = spark.read
        //.format("com.databricks.spark.csv")
        //.option("header", "true") 
        //.option("mode", "DROPMALFORMED")
      //  .load("C:/Users/nageswara.rao.dasari/Downloads/MOCK_DATA (2).csv"); 

    
    //val rdd = sc.textFile("C:/Users/nageswara.rao.dasari/Downloads/MOCK_DATA (2).csv")
 
 //sc.parallelize(List(1,2,3)).flatMap(x=>List(x,x,x)).collect.foreach(println)
 val df1 = sparksql.read
      .format("com.databricks.spark.csv")
      .option("header", "true") 
      .option("mode", "DROPMALFORMED")
      .load("C:/dim/DimSurveyItem.csv");
 
 df1.registerTempTable("DimSurveyItem")
 
 
 val df2 = sparksql.read
      .format("com.databricks.spark.csv")
      .option("header", "true") 
      .option("mode", "DROPMALFORMED")
      .load("C:/dim/DimSurveyItemResponse.csv");
 
 df2.registerTempTable("DimSurveyItemResponse")
 
 
 val df3 = sparksql.read
      .format("com.databricks.spark.csv")
      .option("header", "true") 
      .option("mode", "DROPMALFORMED")
      .load("C:/dim/DimEDWSource.csv");
 
 df3.registerTempTable("DimEDWSource")
 
 
  val df4 = sparksql.read
      .format("com.databricks.spark.csv")
      .option("header", "true") 
      .option("mode", "DROPMALFORMED")
      .load("C:/dim/DimEDWSource.csv");
 
 df4.registerTempTable("dimclientfacility")
 
 

 
 
val a = sparksql.sql("describe dimclientfacility")

a.collect().foreach(println)
  
 
 

 }
}