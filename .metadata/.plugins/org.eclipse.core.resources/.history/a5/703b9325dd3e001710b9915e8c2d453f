package com.pgtest
import org.apache.spark.SparkConf
import org.apache.spark.streaming.StreamingContext
import org.apache.spark.streaming.Seconds
import org.apache.spark.streaming._
import org.apache.spark.streaming.kafka.KafkaUtils
import org.apache.log4j.{ Logger, Level }
import com.datastax.spark.connector.cql.CassandraConnector
import com.datastax.spark.connector.streaming._
import org.apache.spark.SparkConf
import org.apache.spark.SparkContext
import com.datastax.spark.connector._
import com.datastax.spark.connector.rdd._
import org.apache.spark.sql.cassandra._
import com.datastax.spark.connector.cql.CassandraConnector
import java.util.Date
import org.apache.spark.sql._
import org.apache.spark.sql.SQLContext
case class sample(id: String, f_name: String, l_name: String, email: String, gendr: String, ip: String, salary: Float)
object Aggregation {
  def main(args: Array[String]) {

    Logger.getLogger("org").setLevel(Level.OFF)
    Logger.getLogger("akka").setLevel(Level.OFF)

    val conf = new SparkConf().setMaster("local[*]").setAppName("KafkaReceiver").set("spark.driver.allowMultipleContexts", "true").set("spark.cassandra.connection.host", "localhost")
    val sc = new SparkContext(conf);
    val sqlContext = new SQLContext(sc);
    val ssc = new StreamingContext(conf, Seconds(5))

    val messages = KafkaUtils.createStream(ssc, "localhost:2181", "spark-streaming-consumer-group", Map("nagesh" -> 1))

    val rdd1 = messages.map(_._2) // split the message into lines
     /* //.flatMap(_.split(",")) //split into words
      .filter(w => (w.length() > 0))
      .map(_.split(",")).map(z => (z(0), z(1), z(2), z(3), z(4), z(5), z(6)))
    val rdd = rdd1.foreachRDD { rdd =>
      val sqlContext = SQLContext.getOrCreate(rdd.sparkContext)
      import sqlContext.implicits._
      val wordsDataFrame = rdd.toDF("id", "f_name", "l_name", "email", "gender", "ip", "salary")
      wordsDataFrame.registerTempTable("words")
      val wordCountsDataFrame =
        sqlContext.sql("select * from words");
      wordCountsDataFrame.show()
      rdd.saveToCassandra("test", "stream3", SomeColumns("Provider ID", "Address", "Hospital Name"))

    }*/

    ssc.start()
    ssc.awaitTermination()

  }

}